{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3ro7aHT-j1kk"
      },
      "outputs": [],
      "source": [
        "# Experiment Title: Implement text document similarity recognizer for the given text\n",
        "# Experiment No: 03\n",
        "# Author: Adrija Dastidar\n",
        "# PRN: 1032221315"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "94TPF72-kUNR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly2KHy5sktrm",
        "outputId": "b2bbd46c-0304-49a5-d9a4-64cad01ce186"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J9YkU_Pgk2vR"
      },
      "outputs": [],
      "source": [
        "# Sample Documents\n",
        "documents = [\n",
        "    \"This is a sample document for testing the text similarity\",\n",
        "    \"We will use NLTK for computing similarity of text\",\n",
        "    \"NLTK is a powerful library for natural language processing\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vuJdHJ-TlHBT"
      },
      "outputs": [],
      "source": [
        "# Define stop words and stemmer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VjtXkRxtlphQ"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"Tokenizes, removes stopwords, and applies stemming.\"\"\"\n",
        "    words = word_tokenize(text.lower())\n",
        "    filtered_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if word.isalnum() and word not in stop_words:\n",
        "            filtered_words.append(stemmer.stem(word))\n",
        "\n",
        "    return ' '.join(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "L5odom3QnhhV"
      },
      "outputs": [],
      "source": [
        "# Preprocess documents\n",
        "preprocessed_docs = []\n",
        "\n",
        "for doc in documents:\n",
        "    preprocessed_docs.append(preprocess_text(doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqrmF42Vlr2j",
        "outputId": "cd19864c-5905-4f73-9fe1-7d5443149f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed Documents:\n",
            "Document 1: sampl document test text similar\n",
            "Document 2: use nltk comput similar text\n",
            "Document 3: nltk power librari natur languag process\n"
          ]
        }
      ],
      "source": [
        "# Display preprocessed documents\n",
        "print(\"Preprocessed Documents:\")\n",
        "for i in range(len(documents)):\n",
        "    print(f\"Document {i+1}: {preprocess_text(documents[i])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hrd_YXUUl03a"
      },
      "outputs": [],
      "source": [
        "# TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_docs)\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHJ04SdCmwMN",
        "outputId": "82fb88e6-b62e-4292-94ff-f902037f8c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF Matrix:\n",
            "Document 1:\n",
            "\t comput: 0.0000\n",
            "\t document: 0.4905\n",
            "\t languag: 0.0000\n",
            "\t librari: 0.0000\n",
            "\t natur: 0.0000\n",
            "\t nltk: 0.0000\n",
            "\t power: 0.0000\n",
            "\t process: 0.0000\n",
            "\t sampl: 0.4905\n",
            "\t similar: 0.3730\n",
            "\t test: 0.4905\n",
            "\t text: 0.3730\n",
            "\t use: 0.0000\n",
            "Document 2:\n",
            "\t comput: 0.5174\n",
            "\t document: 0.0000\n",
            "\t languag: 0.0000\n",
            "\t librari: 0.0000\n",
            "\t natur: 0.0000\n",
            "\t nltk: 0.3935\n",
            "\t power: 0.0000\n",
            "\t process: 0.0000\n",
            "\t sampl: 0.0000\n",
            "\t similar: 0.3935\n",
            "\t test: 0.0000\n",
            "\t text: 0.3935\n",
            "\t use: 0.5174\n",
            "Document 3:\n",
            "\t comput: 0.0000\n",
            "\t document: 0.0000\n",
            "\t languag: 0.4234\n",
            "\t librari: 0.4234\n",
            "\t natur: 0.4234\n",
            "\t nltk: 0.3220\n",
            "\t power: 0.4234\n",
            "\t process: 0.4234\n",
            "\t sampl: 0.0000\n",
            "\t similar: 0.0000\n",
            "\t test: 0.0000\n",
            "\t text: 0.0000\n",
            "\t use: 0.0000\n"
          ]
        }
      ],
      "source": [
        "# Display TF-IDF matrix\n",
        "print(\"TF-IDF Matrix:\")\n",
        "for i in range(len(documents)):\n",
        "    print(f\"Document {i+1}:\")\n",
        "    for j in range(len(feature_names)):\n",
        "        print(f\"\\t {feature_names[j]}: {tfidf_matrix.toarray()[i, j]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eMMeWPBfPi1A"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "# Get vocabulary from preprocessed documents\n",
        "vocab = set()\n",
        "for doc in preprocessed_docs:\n",
        "    vocab.update(doc.split())\n",
        "\n",
        "# Compute Term Frequency (TF)\n",
        "def compute_tf(doc):\n",
        "    words = doc.split()\n",
        "    word_counts = Counter(words)\n",
        "    total_words = len(words)\n",
        "    return {word: word_counts[word] / total_words for word in vocab}\n",
        "\n",
        "tf_scores = [compute_tf(doc) for doc in preprocessed_docs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WRreUNW1Pjnv"
      },
      "outputs": [],
      "source": [
        "# Compute Inverse Document Frequency (IDF)\n",
        "def compute_idf(docs):\n",
        "    num_docs = len(docs)\n",
        "    idf_scores = {}\n",
        "\n",
        "    for word in vocab:\n",
        "        containing_docs = sum(1 for doc in docs if word in set(doc.split()))\n",
        "        idf_scores[word] = math.log(num_docs / (1 + containing_docs))\n",
        "\n",
        "    return idf_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShlMf9NgP0vF",
        "outputId": "4d34c50c-6560-464c-c363-a93e94f43a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "TF-IDF Scores:\n",
            "\n",
            "Document 1:\n",
            "\tnatur: 0.0000\n",
            "\ttext: 0.0000\n",
            "\tsimilar: 0.0000\n",
            "\tcomput: 0.0000\n",
            "\tsampl: 0.0811\n",
            "\tnltk: 0.0000\n",
            "\tuse: 0.0000\n",
            "\tdocument: 0.0811\n",
            "\tlanguag: 0.0000\n",
            "\ttest: 0.0811\n",
            "\tprocess: 0.0000\n",
            "\tlibrari: 0.0000\n",
            "\tpower: 0.0000\n",
            "\n",
            "Document 2:\n",
            "\tnatur: 0.0000\n",
            "\ttext: 0.0000\n",
            "\tsimilar: 0.0000\n",
            "\tcomput: 0.0811\n",
            "\tsampl: 0.0000\n",
            "\tnltk: 0.0000\n",
            "\tuse: 0.0811\n",
            "\tdocument: 0.0000\n",
            "\tlanguag: 0.0000\n",
            "\ttest: 0.0000\n",
            "\tprocess: 0.0000\n",
            "\tlibrari: 0.0000\n",
            "\tpower: 0.0000\n",
            "\n",
            "Document 3:\n",
            "\tnatur: 0.0676\n",
            "\ttext: 0.0000\n",
            "\tsimilar: 0.0000\n",
            "\tcomput: 0.0000\n",
            "\tsampl: 0.0000\n",
            "\tnltk: 0.0000\n",
            "\tuse: 0.0000\n",
            "\tdocument: 0.0000\n",
            "\tlanguag: 0.0676\n",
            "\ttest: 0.0000\n",
            "\tprocess: 0.0676\n",
            "\tlibrari: 0.0676\n",
            "\tpower: 0.0676\n"
          ]
        }
      ],
      "source": [
        "# Compute TF-IDF\n",
        "idf_scores = compute_idf(preprocessed_docs)\n",
        "tfidf_scores = [{word: tf * idf_scores[word] for word, tf in tf.items()} for tf in tf_scores]\n",
        "\n",
        "print(\"\\nTF-IDF Scores:\")\n",
        "for i, doc_tfidf in enumerate(tfidf_scores):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    for word, score in doc_tfidf.items():\n",
        "        print(f\"\\t{word}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7bYGBg0CobFF"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def calculate_similarity(text1, text2):\n",
        "    preprocessed_texts = [preprocess_text(text1), preprocess_text(text2)]\n",
        "\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_texts)\n",
        "\n",
        "    similarity_score = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "    return similarity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sqmLQygLsAMy"
      },
      "outputs": [],
      "source": [
        "def find_similar_words(text1, text2):\n",
        "    words1 = set(preprocess_text(text1).split())\n",
        "    words2 = set(preprocess_text(text2).split())\n",
        "\n",
        "    common_words = words1.intersection(words2)\n",
        "    return common_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qvcNfn0ZsFTG"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    text1 = \"I enjoy eating apples\"\n",
        "    text2 = \"Apples are sweet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOX6DFcqsJs6",
        "outputId": "4be8a33d-0985-4a27-994f-a9382ab013e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity Score: 0.2606\n"
          ]
        }
      ],
      "source": [
        "similarity_score = calculate_similarity(text1, text2)\n",
        "print(f\"Similarity Score: {similarity_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbzRtBiFsOWg",
        "outputId": "9d6b27be-abb6-45b2-c757-cba0691694a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Common Words: {'appl'}\n"
          ]
        }
      ],
      "source": [
        "similar_words = find_similar_words(text1, text2)\n",
        "print(f\"Common Words: {similar_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szZa7Q6lD2gK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
